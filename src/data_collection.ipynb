{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/deepc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from mpc import mpc\n",
    "from mpc.mpc import QuadCost, LinDx, GradMethods\n",
    "from mpc.env_dx import cartpole\n",
    "import torch\n",
    "from torch.autograd import Function, Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from mpc import util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import tempfile\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3808)\n",
      "tensor(-2.5610)\n",
      "violated\n"
     ]
    }
   ],
   "source": [
    "arr = torch.randn(50,4)\n",
    "print(arr[:,1].max())\n",
    "print(arr[:,1].min())\n",
    "if any(torch.abs(arr[:,1]) >= 2) : print('violated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartpoleDx(nn.Module):\n",
    "    def __init__(self, params=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_state = 4\n",
    "        self.n_ctrl = 1\n",
    "\n",
    "        # model parameters\n",
    "        if params is None:\n",
    "            # gravity, masscart, masspole, length\n",
    "            self.params = Variable(torch.Tensor((9.8, 1.0, 0.1, 0.5)))\n",
    "        else:\n",
    "            self.params = params\n",
    "        assert len(self.params) == 4\n",
    "        self.force_mag = 100.\n",
    "\n",
    "        self.theta_threshold_radians = np.pi#12 * 2 * np.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "        self.max_velocity = 10\n",
    "\n",
    "        self.dt = 0.05\n",
    "\n",
    "        self.lower = -self.force_mag\n",
    "        self.upper = self.force_mag\n",
    "\n",
    "        # 0  1      2        3   4\n",
    "        # x dx cos(th) sin(th) dth\n",
    "        self.goal_state = torch.Tensor(  [ 0.,  0., 0.,   0.])\n",
    "        self.goal_weights = torch.Tensor([100, 100,  100, 100])\n",
    "        self.ctrl_penalty = 0.01\n",
    "\n",
    "        self.mpc_eps = 1e-4\n",
    "        self.linesearch_decay = 0.5\n",
    "        self.max_linesearch_iter = 2\n",
    "\n",
    "    def forward(self, state, u):\n",
    "        squeeze = state.ndimension() == 1\n",
    "\n",
    "        if squeeze:\n",
    "            state = state.unsqueeze(0)\n",
    "            u = u.unsqueeze(0)\n",
    "\n",
    "        if state.is_cuda and not self.params.is_cuda:\n",
    "            self.params = self.params.cuda()\n",
    "        gravity, masscart, masspole, length = torch.unbind(self.params)\n",
    "        total_mass = masspole + masscart\n",
    "        polemass_length = masspole * length\n",
    "\n",
    "        u = torch.clamp(u[:,0], -self.force_mag, self.force_mag)\n",
    "\n",
    "        x, dx, th, dth = torch.unbind(state, dim=1)\n",
    "        # th = torch.atan2(sin_th, cos_th)\n",
    "        cos_th, sin_th = torch.cos(th), torch.sin(th)\n",
    "\n",
    "        cart_in = (u + polemass_length * dth**2 * sin_th) / total_mass\n",
    "        th_acc = (gravity * sin_th - cos_th * cart_in) / \\\n",
    "                 (length * (4./3. - masspole * cos_th**2 /\n",
    "                                     total_mass))\n",
    "        xacc = cart_in - polemass_length * th_acc * cos_th / total_mass\n",
    "\n",
    "        x = x + self.dt * dx\n",
    "        dx = dx + self.dt * xacc\n",
    "        th = th + self.dt * dth\n",
    "        dth = dth + self.dt * th_acc\n",
    "\n",
    "        state = torch.stack((\n",
    "            x, dx, th, dth\n",
    "        ), 1)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def get_frame(self, state, ax=None):\n",
    "        state = util.get_data_maybe(state.view(-1))\n",
    "        assert len(state) == 4\n",
    "        x, dx, th, dth = torch.unbind(state)\n",
    "        cos_th, sin_th = torch.cos(th), torch.sin(th)\n",
    "        gravity, masscart, masspole, length = torch.unbind(self.params)\n",
    "        th = np.arctan2(sin_th, cos_th)\n",
    "        th_x = sin_th*length\n",
    "        th_y = cos_th*length\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "        else:\n",
    "            fig = ax.get_figure()\n",
    "        ax.plot((x,x+th_x), (0, th_y), color='k')\n",
    "        ax.set_xlim((-length*2, length*2))\n",
    "        ax.set_ylim((-length*2, length*2))\n",
    "        return fig, ax\n",
    "\n",
    "    def get_true_obj(self):\n",
    "        q = torch.cat((\n",
    "            self.goal_weights,\n",
    "            self.ctrl_penalty*torch.ones(self.n_ctrl)\n",
    "        ))\n",
    "        assert not hasattr(self, 'mpc_lin')\n",
    "        px = -torch.sqrt(self.goal_weights)*self.goal_state #+ self.mpc_lin\n",
    "        p = torch.cat((px, torch.zeros(self.n_ctrl)))\n",
    "        return Variable(q), Variable(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmp dir: /tmp/tmprk5zey5f\n",
      "torch.Size([1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:04<00:00, 14.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dx = CartpoleDx().to(device='mps')\n",
    "\n",
    "n_batch, T, mpc_T = 1, 70, 20\n",
    "\n",
    "def uniform(shape, low, high):\n",
    "    r = high-low\n",
    "    return torch.rand(shape)*r+low\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "th = uniform(n_batch, -0.01, 0.01)\n",
    "thdot = torch.Tensor([0])\n",
    "x = torch.Tensor([0])\n",
    "xdot = torch.Tensor([0])\n",
    "xinit = torch.stack((x, xdot, th, thdot), dim=1)\n",
    "x = xinit\n",
    "u_init = None\n",
    "\n",
    "q, p = dx.get_true_obj()\n",
    "Q = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "    mpc_T, n_batch, 1, 1\n",
    ")\n",
    "p = p.unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "t_dir = tempfile.mkdtemp()\n",
    "print('Tmp dir: {}'.format(t_dir))\n",
    "\n",
    "controller = mpc.MPC(\n",
    "        dx.n_state, dx.n_ctrl, mpc_T,\n",
    "        u_init=u_init,\n",
    "        u_lower=dx.lower, u_upper=dx.upper,\n",
    "        lqr_iter=50,\n",
    "        verbose=0,\n",
    "        exit_unconverged=False,\n",
    "        detach_unconverged=False,\n",
    "        backprop=False,\n",
    "        linesearch_decay=dx.linesearch_decay,\n",
    "        max_linesearch_iter=dx.max_linesearch_iter,\n",
    "        grad_method=GradMethods.AUTO_DIFF,\n",
    "        eps=1e-2,\n",
    "    ).to(device='mps')\n",
    "\n",
    "print(xinit.shape)\n",
    "# F, f = controller.linearize_dynamics(torch.zeros((mpc_T,n_batch,4)), util.detach_maybe(torch.zeros((mpc_T,n_batch,1))), dx, diff=True)\n",
    "action_history = []\n",
    "state_history= []\n",
    "for i in tqdm(range(T)):\n",
    "    # x += torch.randn(x.shape)*0.001\n",
    "    nominal_states, nominal_actions, nominal_objs = controller(x, QuadCost(Q, p), dx)\n",
    "    \n",
    "    next_action = nominal_actions[0] + torch.randn(1,)*0.001\n",
    "    action_history.append(next_action)\n",
    "    u_init = torch.cat((nominal_actions[1:], torch.zeros(1, n_batch, dx.n_ctrl)), dim=0)\n",
    "    u_init[-2] = u_init[-3]\n",
    "    x = dx(x, next_action) \n",
    "    state_history.append(x)\n",
    "    \n",
    "    n_row, n_col = 1, 1\n",
    "    fig, axs = plt.subplots(n_row, n_col, figsize=(3*n_col,3*n_row))\n",
    "\n",
    "    for r in range(n_batch):\n",
    "        dx.get_frame(x[r], ax=axs)\n",
    "        axs.get_xaxis().set_visible(False)\n",
    "        axs.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(t_dir, '{:03d}.png'.format(i)))\n",
    "    plt.close(fig)\n",
    "    \n",
    "action_history = torch.stack(action_history).detach()[:,:,0]\n",
    "state_history = torch.stack(state_history).detach()[:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_history = state_history.squeeze(1)\n",
    "state_history = state_history.detach().cpu().numpy()\n",
    "action_history = action_history.squeeze(1)\n",
    "action_history = action_history.detach().cpu().numpy()\n",
    "action_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('../cartpole_yd.csv', state_history, delimiter=',')\n",
    "savetxt('../cartpole_ud.csv', action_history, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
