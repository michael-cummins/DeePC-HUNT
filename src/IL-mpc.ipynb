{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/deepc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mpc import mpc\n",
    "from mpc.mpc import QuadCost\n",
    "\n",
    "from IPython.core import ultratb\n",
    "\n",
    "from mpc.dynamics import AffineDynamics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch, n_state, n_ctrl, T = 24, 3, 3, 10\n",
    "n_sc = n_state + n_ctrl\n",
    "device = 'cpu'\n",
    "u_lower = torch.tensor([-0.5,-0.5,-0.5], dtype=torch.float32)\n",
    "u_lower = u_lower.repeat(T, n_batch, 1)\n",
    "u_upper = torch.tensor([0.5,0.5,0.5], dtype=torch.float32)\n",
    "u_upper = u_upper.repeat(T, n_batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = torch.Tensor([2,1,-1])\n",
    "goal_weights = torch.ones(n_state)*10\n",
    "px = -(goal_weights)*goal_state\n",
    "p = torch.cat((px, torch.zeros(n_ctrl)))\n",
    "p = p.unsqueeze(0).repeat(T, n_batch, 1)\n",
    "\n",
    "ctr_penalty = 0.1\n",
    "q = torch.cat([goal_weights, torch.ones(n_ctrl)*ctr_penalty]).to(device)\n",
    "Q = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "        T, n_batch, 1, 1\n",
    ").to(device)\n",
    "A = torch.tensor([[1.01, 0.01, 0],[0.01, 1.01, 0.01],[0, 0.01, 1.01]]).to(device)\n",
    "B = torch.eye(3).to(device)\n",
    "\n",
    "# Initialise Parameters\n",
    "weight_est, ctrl_est = Parameter(torch.randn(size=(3,))*0.1+1), Parameter(torch.randn(size=(3,))*0.1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1150972843170166\n",
      "Parameter containing:\n",
      "tensor([1.0650, 1.0915, 0.9586], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(weight_est.sum().item())\n",
    "print(weight_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.0000, 10.0000, 10.0000,  0.1000,  0.1000,  0.1000])\n",
      "tensor([1.0650, 1.0915, 0.9586, 0.8633, 0.9408, 0.7503],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(q)\n",
    "print(torch.cat([weight_est, ctrl_est]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x_init : torch.Tensor, q_est : torch.Tensor, r_est : torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # Expert \n",
    "        x_true, u_true, objs_true = mpc.MPC(\n",
    "            n_state, n_ctrl, T,\n",
    "            u_lower=u_lower, u_upper=u_upper, \n",
    "            lqr_iter=100,\n",
    "            verbose=-1,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=False,\n",
    "            backprop=False,\n",
    "            n_batch=n_batch,\n",
    "        )(x_init, QuadCost(Q, p), AffineDynamics(A=A, B=B))\n",
    "\n",
    "        # Learner\n",
    "\n",
    "        # Construct cost matrices from ctrl and state penalty\n",
    "        # Weights and penalties are identical for each state so \n",
    "        # We only need to optimize over two scalar variables \"weight_est\" and \"ctrl_est\"\n",
    "\n",
    "        q = torch.cat([q_est, r_est])\n",
    "        Q_est = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                T, n_batch, 1, 1\n",
    "        ).to(device)\n",
    "        px = -(q_est)*goal_state\n",
    "        p_est = torch.cat((px, torch.zeros(n_ctrl)))\n",
    "        p_est = p_est.unsqueeze(0).repeat(T, n_batch, 1)    \n",
    "\n",
    "        # Roll out MPC with estimated cost function\n",
    "        x_pred, u_pred, objs_pred = mpc.MPC(\n",
    "            n_state, n_ctrl, T,\n",
    "            u_lower=u_lower, u_upper=u_upper, \n",
    "            lqr_iter=100,\n",
    "            verbose=-1,\n",
    "            backprop=False,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=False,\n",
    "            n_batch=n_batch,\n",
    "        )(x_init, QuadCost(Q_est, p_est), AffineDynamics(A=A, B=B))\n",
    "\n",
    "        # Get MSE of trajectory\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        objs_pred = objs_pred.repeat(1, 1, 1)\n",
    "        traj_loss = criterion(input=u_pred, target=u_true)\n",
    "        \n",
    "        return traj_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/100 [00:00<?, ?it/s]/opt/conda/envs/deepc/lib/python3.9/site-packages/torch/_tensor.py:662: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "LU, pivots = torch.lu(A, compute_pivots)\n",
      "should be replaced with\n",
      "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "and\n",
      "LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "should be replaced with\n",
      "LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "  LU, pivots, infos = torch._lu_with_info(\n",
      "/opt/conda/envs/deepc/lib/python3.9/site-packages/mpc/pnqp.py:19: UserWarning: torch.lu_solve is deprecated in favor of torch.linalg.lu_solveand will be removed in a future PyTorch release.\n",
      "Note that torch.linalg.lu_solve has its arguments reversed.\n",
      "X = torch.lu_solve(B, LU, pivots)\n",
      "should be replaced with\n",
      "X = torch.linalg.lu_solve(LU, pivots, B) (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2072.)\n",
      "  x_init = -q.unsqueeze(2).lu_solve(*H_lu).squeeze(2) # Clamped in the x assignment.\n",
      "/opt/conda/envs/deepc/lib/python3.9/site-packages/mpc/util.py:36: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  D[I] = d.view(-1)\n",
      "Loss = 0.0000003769, Model Loss = 0.00: 100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adagrad((weight_est, ctrl_est), lr=0.1)\n",
    "pbar = tqdm(range(100), ncols=120)\n",
    "\n",
    "for i in pbar:\n",
    "    x_init = torch.randn(n_batch,n_state)\n",
    "\n",
    "    loss = get_loss(x_init, weight_est, ctrl_est)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # Used to checj the difference in ratio of ctrl cost and state cost\n",
    "    model_loss = np.abs(100 - weight_est.sum().item() / ctrl_est.sum().item())\n",
    "\n",
    "    pbar.set_description(f'Loss = {loss.item():.10f}, Model Loss = {model_loss:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0158, 0.0166, 0.0134], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.5755, 1.6025, 1.4029], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_est"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
