{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy import genfromtxt\n",
    "import torch\n",
    "from deepc_hunt.dynamics import AffineDynamics\n",
    "from deepc_hunt import DeePC, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Control System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = genfromtxt('data/recht_ud.csv', delimiter=',')\n",
    "yd = genfromtxt('data/recht_yd.csv', delimiter=',')\n",
    "\n",
    "# Add noise to simulate uncertainty in data\n",
    "noise_std = 0.1              \n",
    "yd += np.random.rand(*yd.shape)*noise_std\n",
    "ud += np.random.rand(*ud.shape)*noise_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialitse DeePC controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeePC(\n",
       "  (QP_layer): CvxpyLayer()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n = 3 # n = number of states\n",
    "m = 3 # m = number of inputs\n",
    "p = 3 # p = number of output\n",
    "q = m+p # q = number of i/o variables\n",
    "Tini = 4 # Past time horizon                                           \n",
    "Tf = 10 # Future time horizon         \n",
    "T = (m+1)*(Tini + Tf + n) - 1    \n",
    "\n",
    "y_constraints = np.kron(np.ones(Tf), np.array([10,10,10]))\n",
    "u_constraints = np.kron(np.ones(Tf), np.array([5,5,5]))\n",
    "q = torch.ones(3)*50\n",
    "r = torch.ones(3)*2\n",
    "n_batch = 8\n",
    "\n",
    "controller = DeePC(\n",
    "    ud=ud, yd=yd, N=Tf, Tini=Tini, p=3, m=3, n_batch=n_batch, device=device,\n",
    "    y_constraints=y_constraints, u_constraints=u_constraints,\n",
    "    stochastic_y=True, stochastic_u=True, linear=True, q=q, r=r\n",
    ")\n",
    "\n",
    "controller.initialise(lam_y=1e-3, lam_u=1e-3)\n",
    "controller.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor([[1.01, 0.01, 0.00], # A - State-space matrix\n",
    "                  [0.01, 1.01, 0.01], \n",
    "                  [0.00, 0.01, 1.01]])\n",
    "\n",
    "dx = AffineDynamics(A=A, B=torch.eye(3)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DeePC-HUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/70 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inconsistent parameter shapes passed in. Expected parameter 4 to have non-batched shape of (30,) but got torch.Size([8, 60]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Tune regularization params\u001b[39;00m\n\u001b[1;32m      5\u001b[0m deepc_tuner \u001b[38;5;241m=\u001b[39m Trainer(controller\u001b[38;5;241m=\u001b[39mcontroller, env\u001b[38;5;241m=\u001b[39mdx)\n\u001b[0;32m----> 6\u001b[0m final_params \u001b[38;5;241m=\u001b[39m \u001b[43mdeepc_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DeePC-HUNT/deepc_hunt/trainer.py:66\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epochs, time_steps)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Begin simulation \u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(time_steps):\n\u001b[1;32m     63\u001b[0m     \n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Solve for input\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# decision_vars = self.controller(ref=yref, uref=uref.to(self.controller.device), u_ini=u_ini, y_ini=y_ini)\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     decision_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontroller\u001b[49m\u001b[43m(\u001b[49m\u001b[43muref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_ini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_ini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_ini\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     [g, u_pred] \u001b[38;5;241m=\u001b[39m decision_vars[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     69\u001b[0m     sig_y \u001b[38;5;241m=\u001b[39m decision_vars[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m Ey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/DeePC-HUNT/deepc_hunt/controllers.py:222\u001b[0m, in \u001b[0;36mDeePC.forward\u001b[0;34m(self, ref, uref, u_ini, y_ini)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_u:\n\u001b[1;32m    220\u001b[0m     params\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam_u\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batch,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 222\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQP_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolve_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mECOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m g, \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m], out[\u001b[38;5;241m2\u001b[39m], out[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m [g, \u001b[38;5;28minput\u001b[39m, output]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/cvxpylayers/torch/cvxpylayer.py:153\u001b[0m, in \u001b[0;36mCvxpyLayer.forward\u001b[0;34m(self, solver_args, *params)\u001b[0m\n\u001b[1;32m    140\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    141\u001b[0m f \u001b[38;5;241m=\u001b[39m _CvxpyLayerFn(\n\u001b[1;32m    142\u001b[0m     param_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_order,\n\u001b[1;32m    143\u001b[0m     param_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     info\u001b[38;5;241m=\u001b[39minfo,\n\u001b[1;32m    152\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m sol \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deepc-dev/lib/python3.10/site-packages/cvxpylayers/torch/cvxpylayer.py:227\u001b[0m, in \u001b[0;36m_CvxpyLayerFn.<locals>._CvxpyLayerFnFn.forward\u001b[0;34m(ctx, *params)\u001b[0m\n\u001b[1;32m    225\u001b[0m     p_shape \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(p_shape \u001b[38;5;241m==\u001b[39m param_order[i]\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInconsistent parameter shapes passed in. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to have non-batched shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    231\u001b[0m                     i,\n\u001b[1;32m    232\u001b[0m                     q\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m    233\u001b[0m                     p\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    235\u001b[0m ctx\u001b[38;5;241m.\u001b[39mbatch_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ctx\u001b[38;5;241m.\u001b[39mbatch_sizes)\n\u001b[1;32m    236\u001b[0m ctx\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39many(ctx\u001b[38;5;241m.\u001b[39mbatch_sizes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Inconsistent parameter shapes passed in. Expected parameter 4 to have non-batched shape of (30,) but got torch.Size([8, 60])."
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "time_steps = 10\n",
    "\n",
    "# Tune regularization params\n",
    "deepc_tuner = Trainer(controller=controller, env=dx)\n",
    "final_params = deepc_tuner.run(epochs=epochs, time_steps=time_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepc-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
